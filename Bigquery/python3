from airflow.models import DAG
from airflow.utils.dates import days_ago

dag = DAG(
    dag_id='bq_migration',
    schedule_interval='@daily',  # 毎日実行
    start_date=days_ago(2),
)

# 一日分のデータを取得・移行するタスク
def generate_tasks(date):
    with dag:
        export_data = BigQueryExecuteQueryOperator(
            task_id=f'export_data_{date}',
            sql=f"""
                EXPORT DATA OPTIONS(
                    uri='gs://your-bucket/export/{date}/*.parquet'
                ) AS
                SELECT *
                FROM `your-project.your_dataset.your_table` 
                WHERE timestamp BETWEEN '{date} 00:00:00' AND '{date} 23:59:59'
            """,
        )
        # その他の移行タスク...

# 過去30日分のタスクを生成
for n in range(1, 31):
    date = (datetime.now() - timedelta(n)).strftime('%Y%m%d')
    generate_tasks(date)
